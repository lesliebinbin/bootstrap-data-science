{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y = (X[:,0] + X[:,1] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.scatter(X[y == i][:,0], X[y == i][:,1], marker=['o', 'x'][i], color=['b', 'k'][i],\n",
    "    s=1000)\n",
    "    plt.xlabel('Switch 0')\n",
    "    plt.ylabel('Switch 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "y_simple = np.random.binomial(1, .5, size=10)\n",
    "X_simple = np.array([[e] for e in y_simple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (X_simple[:,0][y_simple == 0] == 0).sum()\n",
    "print(f\"In {count} instances, both the switch and the light are off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (X_simple[:,0][y_simple == 1] == 1).sum()\n",
    "print(f\"In {count} instances, both the switch and the light are on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_occurrence(X, y, col=0):\n",
    "    co_occurrence = []\n",
    "    for i in [0, 1]:\n",
    "        counts = [(X[:,col][y == i] == j).sum() for j in [0, 1]]\n",
    "        co_occurrence.append(counts)\n",
    "    return np.array(co_occurrence)\n",
    "M = get_co_occurrence(X_simple, y_simple)\n",
    "assert M[0][0] == 3\n",
    "assert M[1][1] == 7\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple = np.vstack([X_simple, [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_simple = np.hstack([y_simple, [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = get_co_occurrence(X_simple, y_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulb_probs = M[0] / M[0].sum()\n",
    "print(\"When the switch is set to 0, the bulb state probabilities are:\")\n",
    "print(bulb_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulb_probs = M[1] / M[1].sum()\n",
    "print(\"When the switch is set to 1, the bulb state probabilities are:\")\n",
    "print(bulb_probs)\n",
    "prediction = ['off', 'on'][bulb_probs.argmax()]\n",
    "accuracy = bulb_probs.max()\n",
    "print(f\"\\nWe assume the bulb is {prediction} with \"\n",
    "f\"{100 * accuracy:.0f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [.75, 1.]\n",
    "total_accuracy = np.average(accuracies, weights=M.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_if_else(X, y, feature_col=0, feature_name='feature'):\n",
    "    M = get_co_occurrence(X, y, col=feature_col)\n",
    "    probs0, probs1 = [M[i]/M[i].sum() for i in [0, 1]]\n",
    "    if_else = f\"\"\"\n",
    "    if {feature_name} == 0:\n",
    "        prediction = {probs0.argmax()}\n",
    "    else:\n",
    "        prediction = {probs1.argmax()}\n",
    "    \"\"\".strip()\n",
    "    if probs0.argmax() == probs1.argmax():\n",
    "        if_else = f\"prediction = {probs0.argmax()}\"\n",
    "    accuracies = [probs0.max(), probs1.max()]\n",
    "    total_accuracy = np.average(accuracies, weights=M.sum(axis=1))\n",
    "    return if_else, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_else, accuracy = train_if_else(X_simple, y_simple, feature_name='switch')\n",
    "print(if_else)\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"switch{i}\" for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(feature_names):\n",
    "    _, accuracy = train_if_else(X, y, feature_col=i, feature_name=name)\n",
    "    print(f\"The model trained on {name} is {100 * accuracy:.0f}% \" \"accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_off = X[:, 0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_switch0_off = X[is_off]\n",
    "y_switch0_off = y[is_off]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_switch0_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_switch0_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_switch0_off = np.delete(X_switch0_off, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_switch0_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_if_else(X_switch0_off, y_switch0_off, feature_name='switch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch0_off_model, off_accuracy = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_X_y(X, y, filter_col=0, condition=0):\n",
    "    inclusion_criteria = X[:, filter_col] == condition\n",
    "    y_filtered = y[inclusion_criteria]\n",
    "    X_filtered = np.delete(X[inclusion_criteria], filter_col, axis=1)\n",
    "    return X_filtered, y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_switch0_on, y_switch0_on = filter_X_y(X, y, filter_col=0, condition=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_if_else(X_switch0_on, y_switch0_on, feature_name='switch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch0_on_model, on_accuracy = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch0_on_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_if_else(if_else_a, if_else_b, feature_name='feature'):\n",
    "    return f\"\"\"\n",
    "    if {feature_name} == 0:\n",
    "        {add_indent(if_else_a)}\n",
    "    else:\n",
    "        {add_indent(if_else_b)}\n",
    "    \"\"\".strip()\n",
    "def add_indent(if_else):\n",
    "    return '\\n'.join([4 * ' ' + line for line in if_else.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_model = combine_if_else(switch0_off_model, switch0_on_model, feature_name='switch0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [off_accuracy, on_accuracy]\n",
    "weights = [y_switch0_off.size, y_switch0_on.size]\n",
    "total_accuracy = np.average(accuracies, weights=weights)\n",
    "print(f\"Our total accuracy is {100 * total_accuracy:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, feature_col=0, condition=0):\n",
    "    has_condition = X[:, feature_col] == condition\n",
    "    X_a, y_a = [e[has_condition] for e in [X, y]]\n",
    "    X_b, y_b = [e[~has_condition] for e in [X, y]]\n",
    "    X_a, X_b = [np.delete(e, feature_col, axis=1) for e in [X_a, X_b]]\n",
    "    return [X_a, X_b, y_a, y_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a, X_b, y_a, y_b = split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(X_a, X_switch0_off)\n",
    "assert np.array_equal(X_b, X_switch0_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nested_if_else(X, y, split_col=0,\n",
    "    feature_names=['feature1', 'feature1']):\n",
    "    split_name = feature_names[split_col]\n",
    "    simple_model, simple_accuracy = train_if_else(X, y, split_col, split_name)\n",
    "    if simple_accuracy == 1.0:\n",
    "        return (simple_model, simple_accuracy)\n",
    "    X_a, X_b, y_a, y_b = split(X, y, feature_col=split_col)\n",
    "    in_name = feature_names[1 - split_col]\n",
    "    if_else_a, accuracy_a = train_if_else(X_a, y_a, feature_name=in_name)\n",
    "    if_else_b, accuracy_b = train_if_else(X_b, y_b, feature_name=in_name)\n",
    "    nested_model = combine_if_else(if_else_a, if_else_b, split_name)\n",
    "    accuracies = [accuracy_a, accuracy_b]\n",
    "    nested_accuracy = np.average(accuracies, weights=[y_a.size, y_b.size])\n",
    "    if nested_accuracy > simple_accuracy:\n",
    "        return (nested_model, nested_accuracy)\n",
    "    return (simple_model, simple_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['switch0', 'switch1']\n",
    "model, accuracy = train_nested_if_else(X, y, feature_names=feature_names)\n",
    "print(model)\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "y_rain = np.random.binomial(1, .6, size=100)\n",
    "is_wet = [e if np.random.binomial(1, 0.95) else 1 - e for e in y_rain]\n",
    "is_fall = [e if np.random.binomial(1, 0.6) else 1 - e for e in y_rain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rain = np.array([is_fall, is_wet]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['is_autumn', 'is_wet']\n",
    "model, accuracy = train_nested_if_else(X_rain, y_rain,\n",
    "feature_names=feature_names)\n",
    "print(model)\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy = train_nested_if_else(X_rain, y_rain, split_col=1,\n",
    "feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rain = y_rain.sum()/y_rain.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"It rains in {100 * prob_rain:.0f}% of our observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fall_a, y_fall_b = split(X_rain, y_rain, feature_col=0)[-2:]\n",
    "for i, y_fall in enumerate([y_fall_a, y_fall_b]):\n",
    "    prob_rain = y_fall.sum() / y_fall.size\n",
    "    state = ['not autumn', 'autumn'][i]\n",
    "    print(f\"It rains {100 * prob_rain:.0f}% of the time when it is \"\n",
    "    f\"{state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_wet_a, y_wet_b = split(X_rain, y_rain, feature_col=1)[-2:]\n",
    "for i, y_wet in enumerate([y_wet_a, y_wet_b]):\n",
    "    prob_rain = y_wet.sum() / y_wet.size\n",
    "    state = ['not wet', 'wet'][i]\n",
    "    print(f\"It rains {100 * prob_rain:.0f}% of the time when it is \"\n",
    "    f\"{state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(y):\n",
    "    prob_rain = y.sum()/y.size\n",
    "    return np.array([1 - prob_rain, prob_rain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vector(v, label, linestyle='-', color='b'):\n",
    "    plt.plot([0, v[0]], [0, v[1]], label=label, linestyle=linestyle, c=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [y_fall_a, y_fall_b, y_wet_a, y_wet_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [get_class_distribution(y) for y in classes]\n",
    "labels = ['Not Autumn', 'Autumn', 'Not Wet', 'Wet']\n",
    "colors = ['y', 'g', 'k', 'b']\n",
    "linestyles = ['-.', ':', '-', '--']\n",
    "for tup in zip(distributions, labels, colors, linestyles):\n",
    "    vector, label, color, linestyle = tup\n",
    "    plot_vector(vector, label, linestyle=linestyle, color=color)\n",
    "plt.legend()\n",
    "plt.xlabel('Probability Not Rain')\n",
    "plt.ylabel('Probability Rain')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rain = np.arange(0, 1.001, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [np.array([1 - p, p]) for p in prob_rain]\n",
    "magnitudes = [np.linalg.norm(v) for v in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_magnitudes = [v @ v for v in vectors]\n",
    "plt.plot(prob_rain, magnitudes, label='Magnitude')\n",
    "plt.plot(prob_rain, square_magnitudes, label='Squared Magnitude',\n",
    "linestyle='--')\n",
    "plt.xlabel('Probability of Rain')\n",
    "plt.axvline(0.5, color='k', label='Perfect Balance', linestyle=':')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_impurities = [1 - (v @ v) for v in vectors]\n",
    "plt.plot(prob_rain, gini_impurities)\n",
    "plt.xlabel('Probability of Rain')\n",
    "plt.ylabel('Gini Impurity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impurity(y_a, y_b):\n",
    "    v_a = get_class_distribution(y_a)\n",
    "    v_b = get_class_distribution(y_b)\n",
    "    impurities = [1 - v @ v for v in [v_a, v_b]]\n",
    "    weights = [y.size, y_b.size]\n",
    "    return np.average(impurities, weights=weights)\n",
    "fall_impurity = compute_impurity(y_fall_a, y_fall_b)\n",
    "wet_impurity = compute_impurity(y_wet_a, y_wet_b)\n",
    "print(f\"When we split on Autumn, the Impurity is {fall_impurity:0.2f}.\")\n",
    "print(f\"When we split on Wetness, the Impurity is {wet_impurity:0.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_feature_indices(X, y):\n",
    "    feature_indices = range(X.shape[1])\n",
    "    impurities = []\n",
    "    for i in feature_indices:\n",
    "        y_a, y_b = split(X, y, feature_col=i)[-2:]\n",
    "        impurities.append(compute_impurity(y_a, y_b))\n",
    "    return sorted(feature_indices, key=lambda i: impurities[i])\n",
    "indices = sort_feature_indices(X_rain, y_rain)\n",
    "top_feature = feature_names[indices[0]]\n",
    "print(f\"The feature with the minimal impurity is: '{top_feature}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_weather():\n",
    "    is_fall = np.random.binomial(1, .25)\n",
    "    is_cloudy = np.random.binomial(1, [.3, .7][is_fall])\n",
    "    rained_today = np.random.binomial(1, [.05, .4][is_cloudy])\n",
    "    if rained_today:\n",
    "        rains_tomorrow = np.random.binomial(1, .5)\n",
    "    else:\n",
    "        rains_tomorrow = np.random.binomial(1, [.05, .15][is_fall])\n",
    "    features = [rained_today, is_fall, is_cloudy]\n",
    "    return features, rains_tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, y_train = [], []\n",
    "for _ in range(1000):\n",
    "    features, rains_tomorrow = simulate_weather()\n",
    "    X_train.append(features)\n",
    "    y_train.append(rains_tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rain = np.array(X_train)\n",
    "y_rain = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['rained_today', 'is_fall', 'is_cloudy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = sort_feature_indices(X_rain, y_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features sorted by Gini Impurity:\")\n",
    "print([feature_names[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset = np.delete(X_rain, skip_index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subset = np.delete(feature_names, skip_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = indices[0] if indices[0] < skip_index else indices[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy = train_nested_if_else(X_subset, y_rain, split_col=split_col, feature_names=name_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a, X_b, y_a, y_b = split(X_rain, y_rain, feature_col=indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_subset = np.delete(feature_names, indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = sort_feature_indices(X_a, y_a)[0]\n",
    "model_a, accuracy_a = train_nested_if_else(X_a, y_a, split_col=split_col, feature_names=name_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"If it is not autumn, then the following nested model is \" f\"{100 * accuracy_a:.0f}% accurate.\\n\\n{model_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = sort_feature_indices(X_b, y_b)[0]\n",
    "model_b, accuracy_b = train_nested_if_else(X_b, y_b, split_col=split_col, feature_names=name_subset)\n",
    "print(\"If it is autumn, then the following nested model is \"\n",
    "f\"{100 * accuracy_b:.0f}% accurate.\\n\\n{model_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_model = combine_if_else(model_a, model_b, feature_names[indices[0]])\n",
    "print(nested_model)\n",
    "accuracies = [accuracy_a, accuracy_b]\n",
    "accuracy = np.average(accuracies, weights=[y_a.size, y_b.size])\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, feature_names):\n",
    "    if X.shape[1] == 1:\n",
    "        return train_if_else(X, y, feature_name=feature_names[0])\n",
    "    indices = sort_feature_indices(X, y)\n",
    "    X_subset = np.delete(X, indices[-1], axis=1)\n",
    "    name_subset = np.delete(feature_names, indices[-1])\n",
    "    simple_model, simple_accuracy = train(X_subset, y, name_subset)\n",
    "    if simple_accuracy == 1.0:\n",
    "        return (simple_model, simple_accuracy)\n",
    "    split_col = indices[0]\n",
    "    name_subset = np.delete(feature_names, split_col)\n",
    "    X_a, X_b, y_a, y_b = split(X, y, feature_col=split_col)\n",
    "    model_a, accuracy_a = train(X_a, y_a, name_subset)\n",
    "    model_b, accuracy_b = train(X_b, y_b, name_subset)\n",
    "    accuracies = [accuracy_a, accuracy_b]\n",
    "    total_accuracy = np.average(accuracies, weights=[y_a.size, y_b.size])\n",
    "    nested_model = combine_if_else(model_a, model_b, feature_names[split_col])\n",
    "    if total_accuracy > simple_accuracy:\n",
    "        return (nested_model, total_accuracy)\n",
    "    return (simple_model, simple_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy = train(X_rain, y_rain, feature_names)\n",
    "print(model)\n",
    "print(f\"\\nThis statement is {100 * accuracy:.0f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Switch 0', 'Switch 1']\n",
    "class_names = ['Off', 'On']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(clf, feature_names=feature_names, class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "text_tree = export_text(clf, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "feature = np.random.normal(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (feature >= .7).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_impurities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_left = y[feature < threshold]\n",
    "    y_right = y[feature >= threshold]\n",
    "    impurity = compute_impurity(y_left, y_right)\n",
    "    gini_impurities.append(impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh = thresholds[np.argmin(gini_impurities)]\n",
    "print(f\"impurity is minimized at a threshold of {best_thresh:.02f}\")\n",
    "plt.plot(thresholds, gini_impurities)\n",
    "plt.axvline(best_thresh, c='k', linestyle='--')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('impurity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "clf.fit(X, y)\n",
    "feature_names = load_wine().feature_names\n",
    "text_tree = export_text(clf, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(X, y)\n",
    "text_tree = export_text(clf, feature_names=feature_names)\n",
    "print(text_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.argsort(clf.feature_importances_)[::-1]:\n",
    "    feature = feature_names[i]\n",
    "    importance = clf.feature_importances_[i]\n",
    "    if importance == 0:\n",
    "        break\n",
    "    print(f\"'{feature}' has an importance score of {importance:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cancer dataset contains the following {num_classes} classes:\")\n",
    "print(data.target_names)\n",
    "print(f\"\\nIt contains these {num_features} features:\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.argsort(clf.feature_importances_)[::-1]:\n",
    "    feature = feature_names[i]\n",
    "    importance = clf.feature_importances_[i]\n",
    "    if round(importance, 2) == 0:\n",
    "        break\n",
    "    print(f\"'{feature}' has an importance score of {importance:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = clf.feature_importances_.argmax()\n",
    "plt.hist(X[y==0][:, index], label='Maligant', bins='auto')\n",
    "plt.hist(X[y==1][:, index], label='Benign', bins='auto')\n",
    "plt.xlabel('Worst Radius')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our classifier has memorized the training data with \"\n",
    "f\"{100 * accuracy:.0f}% accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = [DecisionTreeClassifier() for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y):\n",
    "    num_rows = X.shape[0]\n",
    "    indices = np.random.choice(range(num_rows), size=num_rows, replace=True)\n",
    "    X_new, y_new = X[indices], y[indices]\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_train_new, y_train_new = bootstrap(X_train, y_train)\n",
    "assert X_train.shape == X_train_new.shape\n",
    "assert y_train.size == y_train_new.size\n",
    "assert not np.array_equal(X_train, X_train_new)\n",
    "assert not np.array_equal(y_train, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "features_train, classes_train = [], []\n",
    "for _ in range(100):\n",
    "    X_train_new, y_train_new = bootstrap(X_train, y_train)\n",
    "    features_train.append(X_train_new)\n",
    "    classes_train.append(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample_size = int(X.shape[1] ** 0.5)\n",
    "assert sample_size == 5\n",
    "feature_indices = [np.random.choice(range(30), 5, replace=False) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, index_subset in enumerate(feature_indices):\n",
    "    features_train[i] = features_train[i][:, index_subset]\n",
    "for index in [0, 99]:\n",
    "    index_subset = feature_indices[index]\n",
    "    names = feature_names[index_subset]\n",
    "    print(f\"\\nRandom features utilized by Tree {index}:\")\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, clf_tree in enumerate(forest):\n",
    "    clf_tree.fit(features_train[i], classes_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "feature_vector = X_test[0]\n",
    "votes = []\n",
    "for i, clf_tree in enumerate(forest):\n",
    "    index_subset = feature_indices[i]\n",
    "    vector_subset = feature_vector[index_subset]\n",
    "    prediction = clf_tree.predict([vector_subset])[0]\n",
    "    votes.append(prediction)\n",
    "class_to_votes = Counter(votes)\n",
    "for class_label, votes in class_to_votes.items():\n",
    "    print(f\"We counted {votes} votes for class {class_label}.\")\n",
    "top_class = max(class_to_votes.items(), key=lambda x: x[1])[0]\n",
    "print(f\"\\nClass {top_class} has received the plurality of the votes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = y_test[0]\n",
    "print(f\"The true class of the data-point is {true_label}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, clf_tree in enumerate(forest):\n",
    "    index_subset = feature_indices[i]\n",
    "    prediction = clf_tree.predict(X_test[:, index_subset])\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [Counter(predictions[:,i]).most_common()[0][0] for i in range(y_test.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_forest = RandomForestClassifier()\n",
    "clf_forest.fit(X_train, y_train)\n",
    "y_pred = clf_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"The forest has predicted the validation outputs with \" f\"{100 * accuracy:.0f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "clf_forest = RandomForestClassifier(n_estimators=10)\n",
    "clf_forest.fit(X_train, y_train)\n",
    "y_pred = clf_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(\"The 10-tree forest has predicted the validation outputs with \" f\"{100 * accuracy:.0f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.argsort(clf_forest.feature_importances_)[::-1][:3]:\n",
    "    feature = feature_names[i]\n",
    "    importance = clf_forest.feature_importances_[i]\n",
    "    print(f\"'{feature}' has an importance score of {importance:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

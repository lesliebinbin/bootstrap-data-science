{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(remove=('headers', 'footers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups.target_names[newsgroups.target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = newsgroups.target_names[newsgroups.target[0]]\n",
    "print(f\"The post at index 0 first appeared in the '{origin}' group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = vectorizer.fit_transform(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_np_matrix = tf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vector = tf_np_matrix[0]\n",
    "non_zero_indices = np.flatnonzero(tf_vector)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "unique_words = [words[index] for index in non_zero_indices]\n",
    "data = {'Word': unique_words,\n",
    "'Count': tf_vector[non_zero_indices]}\n",
    "df = pd.DataFrame(data).sort_values('Count', ascending=False)\n",
    "print(f\"After stop-word deletion, {df.shape[0]} unique words remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_matrix = tf_np_matrix[:, non_zero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix = binarize(sub_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_post_mentions = binary_matrix.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_post_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_post_mentions = binarize(tf_np_matrix[:,non_zero_indices]).sum(axis=0)\n",
    "csr_post_mentions = binarize(tf_matrix[:,non_zero_indices]).sum(axis=0)\n",
    "print(f'NumPy matrix-generated counts:\\n {np_post_mentions}\\n')\n",
    "print(f'CSR matrix-generated counts:\\n {csr_post_mentions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(newsgroups.data)\n",
    "document_frequencies = unique_post_mentions / dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Word': unique_words,\n",
    "'Count': tf_vector[non_zero_indices],\n",
    "'Document Frequency': document_frequencies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_words = df[df['Document Frequency'] > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(['Count','Document Frequency'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_document_frequencies = 1 / document_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IDF'] = inverse_document_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined'] = df.Count * df.IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('Combined', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined'] = df.Count * np.log10(df.IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('Combined', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(newsgroups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tfidf_matrix.shape == tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(tfidf_vectorizer.get_feature_names_out() == words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_np_matrix = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf_np_matrix[0]\n",
    "tfidf_non_zero_indices = np.flatnonzero(tfidf_vector)\n",
    "assert np.array_equal(tfidf_non_zero_indices,\n",
    "non_zero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TFIDF'] = tfidf_vector[non_zero_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_old = df.sort_values('Combined', ascending=False)\n",
    "df_sorted_new = df.sort_values('TFIDF', ascending=False)\n",
    "assert np.array_equal(df_sorted_old['Word'].values, df_sorted_new['Word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(df.TFIDF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_np_matrix @ tfidf_np_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(cosine_similarities)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_index = np.argsort(cosine_similarities)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarities[most_similar_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_post = newsgroups.data[most_similar_index]\n",
    "print(f\"The following post has a cosine similarity of {similarity:.2f} \"\n",
    "\"with newsgroups.data[0]:\\n\")\n",
    "print(most_similar_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_svd = TruncatedSVD(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shrunk_matrix = truncated_svd.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrunk_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude = np.linalg.norm(shrunk_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrunk_norm_matrix = normalize(shrunk_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrunk_norm_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrunk_norm_matrix @ shrunk_norm_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_matrix = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "index1 = np.random.randint(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2 = np.argsort(cosine_similarity_matrix[index1])[-2]\n",
    "similarity = cosine_similarity_matrix[index1][index2]\n",
    "print(f\"The posts at indices {index1} and {index2} share a cosine \" f\"similarity of {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newsgroups.data[index1].replace('\\n\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newsgroups.data[index2].replace('\\n\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "cluster_model = DBSCAN(eps=.4, min_samples=50, metric='cosine')\n",
    "clusters = cluster_model.fit_predict(shrunk_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = clusters.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "import time\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "times = []\n",
    "k = 20\n",
    "for KMeans_class in [KMeans, MiniBatchKMeans]:\n",
    "    start = time.time()\n",
    "    KMeans_class(k).fit(shrunk_norm_matrix)\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "running_time_ratio = times[0] / times[1]\n",
    "print(f\"Mini Batch K-means ran {running_time_ratio:.2f} times faster than regular K-means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "k_values = range(1, 61)\n",
    "inertia_values = [MiniBatchKMeans(k).fit(shrunk_norm_matrix).inertia_ for k in k_values]\n",
    "plt.plot(k_values, inertia_values)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.axvline(20, c='k')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "cluster_model = KMeans(n_clusters=20)\n",
    "clusters = cluster_model.fit_predict(shrunk_norm_matrix)\n",
    "df = pd.DataFrame({'Index': range(dataset_size), 'Cluster': clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = df[df.Cluster == clusters[0]]\n",
    "cluster_size = df_car.shape[0]\n",
    "print(f\"{cluster_size} posts cluster together with the car-themed post at index 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def get_post_category(index):\n",
    "    return newsgroups.target_names[newsgroups.target[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.choice(df_car.Index.values)\n",
    "post_category = get_post_category(random_index)\n",
    "print(f\"This post appeared in the {post_category} discussion group:\\n\")\n",
    "print(newsgroups.data[random_index].replace('\\n\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_autos_count = 0\n",
    "for index in df_car.Index.values:\n",
    "    if get_post_category(index) == 'rec.autos':\n",
    "        rec_autos_count += 1\n",
    "rec_autos_percent = 100 * rec_autos_count / cluster_size\n",
    "print(f\"{rec_autos_percent:.2f}% of posts within the cluster appeared \"\n",
    "\"in the rec.autos discussion group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "not_autos_indices = [index for index in df_car.Index.values\n",
    "if get_post_category(index) != 'rec.autos']\n",
    "random_index = np.random.choice(not_autos_indices)\n",
    "post_category = get_post_category(random_index)\n",
    "print(f\"This post appeared in the {post_category} discussion group:\\n\")\n",
    "print(newsgroups.data[random_index].replace('\\n\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_words_by_tfidf(indices, word_list=words):\n",
    "    summed_tfidf = np.asarray(tfidf_matrix[indices].sum(axis=0)).ravel()\n",
    "    data = {'Word': word_list, 'Summed TFIDF': summed_tfidf}\n",
    "    return pd.DataFrame(data).sort_values('Summed TFIDF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_words = rank_words_by_tfidf(not_autos_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_words = rank_words_by_tfidf(df_car.Index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranked_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x_coord in np.arange(0, 1, .2):\n",
    "    for y_coord in np.arange(0, 1, .2):\n",
    "        word, significance = df_ranked_words.iloc[i].values\n",
    "        plt.text(y_coord, x_coord, word, fontsize=2 * significance)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud_generator = WordCloud(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_score = {word: score for word, score in df_ranked_words[:10].values}\n",
    "wordcloud_image = cloud_generator.fit_words(words_to_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_image = WordCloud(random_state=1, background_color='white').fit_words(words_to_score)\n",
    "plt.imshow(wordcloud_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_image = WordCloud(random_state=1, background_color='white').fit_words(words_to_score)\n",
    "plt.imshow(wordcloud_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_generator = WordCloud(background_color='white',\n",
    "random_state=1)\n",
    "wordcloud_image = cloud_generator.fit_words(words_to_score)\n",
    "plt.imshow(wordcloud_image, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def cluster_to_image(df_cluster, max_words=15):\n",
    "    indices = df_cluster.Index.values\n",
    "    df_ranked_words = rank_words_by_tfidf(indices)[:max_words]\n",
    "    words_to_score = {word: score for word, score in df_ranked_words[:max_words].values}\n",
    "    cloud_generator = WordCloud(background_color='white', color_func=_color_func, random_state=1)\n",
    "    wordcloud_image = cloud_generator.fit_words(words_to_score)\n",
    "    return wordcloud_image\n",
    "def _color_func(*args, **kwargs):\n",
    "    return np.random.choice(['black', 'blue', 'teal', 'purple', 'brown'])\n",
    "cluster_id = np.random.randint(0, 20)\n",
    "df_random_cluster = df[df.Cluster == cluster_id]\n",
    "wordcloud_image = cluster_to_image(df_random_cluster)\n",
    "plt.imshow(wordcloud_image, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_top_category(df_cluster):\n",
    "    categories = [get_post_category(index) for index in df_cluster.Index.values]\n",
    "    top_category, _ = Counter(categories).most_common()[0]\n",
    "    return top_category\n",
    "top_category = get_top_category(df_random_cluster)\n",
    "print(\"The posts within the cluster commonly appear in the \"\n",
    "f\"'{top_category}' newsgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2, 2)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        x = np.arange(0, 1, .2)\n",
    "        y = r*x*x + c*x\n",
    "        axes[r,c].plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2, 2)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        if (r, c) == (1, 0):\n",
    "            axes[r][c].set_title(top_category)\n",
    "            axes[r][c].imshow(wordcloud_image, interpolation=\"bilinear\")\n",
    "        else:\n",
    "            x = np.arange(0, 1, .2)\n",
    "            y = r * x * x + c * x\n",
    "            axes[r][c].plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def get_title(df_cluster):\n",
    "    top_category = get_top_category(df_cluster)\n",
    "    cluster_id = df_cluster.Cluster.values[0]\n",
    "    return f\"{cluster_id}: {top_category}\"\n",
    "figure, axes = plt.subplots(5, 4, figsize=(20, 15))\n",
    "cluster_groups = list(df.groupby('Cluster'))\n",
    "for r in range(5):\n",
    "    for c in range(4):\n",
    "        _, df_cluster = cluster_groups.pop(0)\n",
    "        wordcloud_image = cluster_to_image(df_cluster)\n",
    "        ax = axes[r, c]\n",
    "        ax.imshow(wordcloud_image, interpolation=\"bilinear\")\n",
    "        ax.set_title(get_title(df_cluster))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "df_cluster= df[df.Cluster == 7]\n",
    "df_ranked_words = rank_words_by_tfidf(df_cluster.Index.values)\n",
    "words_to_score = {word: score\n",
    "for word, score in df_ranked_words[10:25].values}\n",
    "cloud_generator = WordCloud(background_color='white',\n",
    "color_func=_color_func,\n",
    "random_state=1)\n",
    "wordcloud_image = cloud_generator.fit_words(words_to_score)\n",
    "plt.imshow(wordcloud_image, interpolation=\"bilinear\")\n",
    "plt.title(get_title(df_cluster), fontsize=20)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
